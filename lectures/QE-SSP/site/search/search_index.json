{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Overview","text":"<p>This course is a solid-state physics and hands-on tutorial for using Quantum ESPRESSO, an open software for quantum calculations for the electronic structure of materials. When we design a new material, the electronic structure calculation is essential to discuss the origin of the material's physical properties, particularly for semiconductors. Nowadays, many researchers and students can run Quantum ESPRESSO on personal computers without paying for the software. Thus, this course is essential for students who want to understand the physics of materials for their experiments or applications.</p> <p>If you have corrections or suggestions, please raise an comment on Github.</p>"},{"location":"contents.html","title":"Contents","text":"<ol> <li> <p>Introduction </p> <ul> <li>Overview </li> <li>What is DFT</li> <li>Install QE</li> <li>Exercise: Getting started </li> </ul> </li> <li> <p>Productivity tools </p> <ul> <li>Ubuntu command</li> <li>JupyterLab</li> <li>Exercise: Crystal hardness </li> </ul> </li> <li> <p>Hands-on tutorials of QE I: Basics parameters </p> <ul> <li>Terminology</li> <li>Learning by example<ul> <li>Supervised</li> <li>Unsupervised</li> <li>Reinforcement</li> </ul> </li> <li>Exercise: Crystal hardness </li> </ul> </li> <li> <p>Hands-on tutorials of QE II: Electronic properties</p> <ul> <li>Data sources and formats</li> <li>API queries </li> <li>Exercise: Data-driven thermoelectrics </li> </ul> </li> <li> <p>Hands-on tutorials of QE III: Phonon properties</p> <ul> <li>Compositional </li> <li>Structural</li> <li>Graphs   </li> <li>Exercise: Navigating crystal space </li> </ul> </li> <li> <p>Hands-on tutorials of QE IV: Optical properties</p> <ul> <li>k-nearest neighbours</li> <li>k-means clustering</li> <li>Decision trees and beyond</li> <li>Exercise: Metal or insulator? </li> </ul> </li> <li> <p>Hands-on tutorials of QE V: Subjects for 2D materials</p> <ul> <li>From neuron to perceptron</li> <li>Network architecture and training</li> <li>Convolutional neural networks   </li> <li>Exercise: Learning microstructure </li> </ul> </li> <li> <p>Hands-on tutorials of QE VI: Wannier90</p> <ul> <li>Data preparation</li> <li>Model choice</li> <li>Training and testing </li> <li>Exercise: Crystal hardness II </li> </ul> </li> <li> <p>Special topic I: QERaman - Raman spectra calculation </p> <ul> <li>Automated experiments </li> <li>Bayesian optimisation</li> <li>Reinforcement learning  </li> <li>Exercise: Closed-loop optimisation </li> </ul> </li> <li> <p>Special topic II: Applications of DFT in materials research </p> <ul> <li>Large language models </li> <li>From latent space to diffusion</li> <li>Exercise: Research challenge </li> </ul> </li> </ol>"},{"location":"lecture1.html","title":"1. Introduction","text":"<p>Lecture slides</p> In\u00a0[\u00a0]: Copied! <pre>2+3 # run this cell\n</pre> 2+3 # run this cell In\u00a0[\u00a0]: Copied! <pre>print(\"Beware of \u5c0f\u5996\u7cbe\") # anything after '#' is a comment and ignored\n</pre> print(\"Beware of \u5c0f\u5996\u7cbe\") # anything after '#' is a comment and ignored In\u00a0[\u00a0]: Copied! <pre>12*2.40*3737*12 # you get the idea\n</pre> 12*2.40*3737*12 # you get the idea In\u00a0[\u00a0]: Copied! <pre>2**1000 - 2 # a big number\n</pre> 2**1000 - 2 # a big number In\u00a0[\u00a0]: Copied! <pre>import math as m # import a math module\nm.pi\n</pre> import math as m # import a math module m.pi In\u00a0[\u00a0]: Copied! <pre>20*m.atan(1/7)+8*m.atan(3/79) # Euler's approximation\n</pre> 20*m.atan(1/7)+8*m.atan(3/79) # Euler's approximation <p>Let's import the package Matplotlib, which we will be using a lot for data visualisation.</p> In\u00a0[\u00a0]: Copied! <pre># Imports\nimport matplotlib.pyplot as plt  # Plotting\nimport numpy as np  # Numerical operations\n%matplotlib inline\n\nx = np.arange(0, 10, 0.001) # x = 0 to 10 in steps of 0.001\ny = np.sin(x*x) # define your function\nplt.figure(figsize=(5, 3)) # create a new figure (5x3 inches)\nplt.plot(,y) # plot x against y\n</pre> # Imports import matplotlib.pyplot as plt  # Plotting import numpy as np  # Numerical operations %matplotlib inline  x = np.arange(0, 10, 0.001) # x = 0 to 10 in steps of 0.001 y = np.sin(x*x) # define your function plt.figure(figsize=(5, 3)) # create a new figure (5x3 inches) plt.plot(,y) # plot x against y  Code hint  You need to plot x vs y. Fix the plot command to (x,y).  In\u00a0[\u00a0]: Copied! <pre>import pandas as pd  # Data manipulation using DataFrames\n\ndf = pd.DataFrame() # This instantiates an empty pandas DataFrame\n\ndata = {\n    \"Element\" : ['C', 'O', 'Fe', 'Mg', 'Xe'],\n    \"Atomic Number\" : [6, 8, 26, 12, 54],\n    \"Atomic Mass\" : [12, 16, 56, 24, 131]\n}\n\n# Let's try loading data into DataFrame df\ndf = pd.DataFrame(data)\n\n# We can make the 'Element' column the index using the set_index function\ndf = df.set_index(\"Element\")\n\n# Printing the values in the 'Atomic Number' column\nprint(df[\"Atom Number\"])\n</pre> import pandas as pd  # Data manipulation using DataFrames  df = pd.DataFrame() # This instantiates an empty pandas DataFrame  data = {     \"Element\" : ['C', 'O', 'Fe', 'Mg', 'Xe'],     \"Atomic Number\" : [6, 8, 26, 12, 54],     \"Atomic Mass\" : [12, 16, 56, 24, 131] }  # Let's try loading data into DataFrame df df = pd.DataFrame(data)  # We can make the 'Element' column the index using the set_index function df = df.set_index(\"Element\")  # Printing the values in the 'Atomic Number' column print(df[\"Atom Number\"])  Code hint  Check you are printing the correct column name. Try out some of the other options.  In\u00a0[\u00a0]: Copied! <pre># Add a new column\ndf[\"Energy (eV)\"] = [5.47, 5.14, 0.12, 4.34, 7.01]\n\nprint(df[\"Energy (eV)\"])\n</pre> # Add a new column df[\"Energy (eV)\"] = [5.47, 5.14, 0.12, 4.34, 7.01]  print(df[\"Energy (eV)\"]) In\u00a0[\u00a0]: Copied! <pre># Print a row from the DataFrame\n\n# The df.loc[index] function to print the entry \"C\"\nprint(df.loc[''])\n\nprint('-----')\n\n# The df.iloc[index] function to print the first entry (counting starts at 0...)\nprint(df.iloc[0])\n</pre> # Print a row from the DataFrame  # The df.loc[index] function to print the entry \"C\" print(df.loc[''])  print('-----')  # The df.iloc[index] function to print the first entry (counting starts at 0...) print(df.iloc[0])  Code hint  You need to tell `df.loc` what to look for. Put an element name in between the quotes.  <p>This equation is written in LaTeX format. It's easy to learn and useful for complex expressions, e.g. <code>\\frac{x}{y}</code> writes x/y as a fraction $\\dfrac{x}{y}$.</p> <p><code>$-\\frac{\\hslash^2}{2m} \\, \\frac{\\partial^2 \\psi}{\\partial x^2}$</code></p> <p>renders as</p> <p>$-\\dfrac{\\hslash^2}{2m} \\, \\dfrac{\\partial^2 \\psi}{\\partial x^2}$</p> <p>The syntax employed here is Markdown. It can be used in notebooks, is popular on Github for documentation, and can even be a fast way to take notes during lectures.</p> <p><code>![](https://media.giphy.com/media/cxk3z6nMhpf7a/giphy.gif)</code></p> <p>which renders as</p> <p></p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nfrom scipy.constants import physical_constants\n\n# Define constants\nk_B = physical_constants['Boltzmann constant in eV/K'][0]\n\n# Arrhenius function\ndef arrhenius(activation_energy, temperature, D0=1):\n    \"\"\"\n    Calculates the rate using the Arrhenius equation.\n    \n    Parameters:\n    activation_energy (float): the activation energy in eV.\n    temperature (float): the temperature in K (must be &gt; 0).\n    D0 (float): the pre-exponential factor (default is 1).\n    \n    Returns:\n    float: the rate of the reaction.\n    \"\"\"\n    if np.any(temperature &lt;= 0):\n        raise ValueError(\"Temperature must be greater than 0 K\")\n    return D0 * np.exp(-activation_energy / (k_B * temperature))\n</pre> import numpy as np from scipy.constants import physical_constants  # Define constants k_B = physical_constants['Boltzmann constant in eV/K'][0]  # Arrhenius function def arrhenius(activation_energy, temperature, D0=1):     \"\"\"     Calculates the rate using the Arrhenius equation.          Parameters:     activation_energy (float): the activation energy in eV.     temperature (float): the temperature in K (must be &gt; 0).     D0 (float): the pre-exponential factor (default is 1).          Returns:     float: the rate of the reaction.     \"\"\"     if np.any(temperature &lt;= 0):         raise ValueError(\"Temperature must be greater than 0 K\")     return D0 * np.exp(-activation_energy / (k_B * temperature)) <p>This function takes <code>activation_energy</code> (eV) and <code>temperature</code> (K) as inputs and returns the corresponding diffusion coefficient. Recall that the units of the exponential term cancel out, so $D_{ion}$ takes the same units as $D_0$. Now let's use the function:</p> In\u00a0[\u00a0]: Copied! <pre> # Call the function for Ea = 0.12 eV; T = 1000 K\narrhenius(0.12, 1000) \n</pre>  # Call the function for Ea = 0.12 eV; T = 1000 K arrhenius(0.12, 1000)  <p>This value tells us the likelihood that each attempt has of overcoming the thermodynamic barrier for ionic diffusion. Decrease the temperature to 100 K and see the difference.</p> <p>Now let's take advantage of the function to make a plot. We will use the numpy function <code>linspace</code>, which is documented over here. It is used here to generate 100 numbers evenly spaced between 100 and 5000 that represent the temperature range of our \"experiments\".</p> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\n\n# Pre-exponential term in cm^2/s\nD0 = 0.5\n\n# Range of activation energies in eV\nactivation_energies = np.linspace(0.1, 1, 0) # Range from 0.1 to 1 eV in n steps\n\n# Temperature range in K\nT = np.linspace(100, 5000, 100)\n\n# Calculate rates and plot curves\nplt.figure(figsize=(5, 3)) \n\nfor activation_energy in activation_energies:\n    rates = arrhenius(activation_energy, T, D0)\n    plt.plot(T, rates, label=f'{activation_energy:.1f} eV')\n\nplt.xlabel('Temperature (K)')\nplt.ylabel('$D_{ion}$ (cm$^2$/s)') \nplt.title('Varying activation energy')\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> import matplotlib.pyplot as plt  # Pre-exponential term in cm^2/s D0 = 0.5  # Range of activation energies in eV activation_energies = np.linspace(0.1, 1, 0) # Range from 0.1 to 1 eV in n steps  # Temperature range in K T = np.linspace(100, 5000, 100)  # Calculate rates and plot curves plt.figure(figsize=(5, 3))   for activation_energy in activation_energies:     rates = arrhenius(activation_energy, T, D0)     plt.plot(T, rates, label=f'{activation_energy:.1f} eV')  plt.xlabel('Temperature (K)') plt.ylabel('$D_{ion}$ (cm$^2$/s)')  plt.title('Varying activation energy') plt.legend() plt.grid(True) plt.show()  Code hint  'np.linspace' requires three arguments (start, stop, number of points). 0 points won't work. Try changing it to 5.  <p>To better visualise the trends, we can make an Arrhenius plot by plotting the natural logarithm of $D$ versus the inverse temperature, 1/T.  We use 1000/T to give a nicer range on the $x$-axis.</p> In\u00a0[\u00a0]: Copied! <pre># Plotting ln(R) vs 1000/T\nplt.figure(figsize=(5, 3)) \n\nfor activation_energy in activation_energies:\n    rates = arrhenius(activation_energy, T, D0)\n    plt.plot(1000/T, np.log(rates), label=f'{activation_energy:.1f} eV')\n\nplt.xlabel('1000 / Temperature (1/K)')\nplt.ylabel('ln($D_{ion}$)')\nplt.title('Arrhenius plot')\nplt.legend()\nplt.grid(True)\nplt.show()\n</pre> # Plotting ln(R) vs 1000/T plt.figure(figsize=(5, 3))   for activation_energy in activation_energies:     rates = arrhenius(activation_energy, T, D0)     plt.plot(1000/T, np.log(rates), label=f'{activation_energy:.1f} eV')  plt.xlabel('1000 / Temperature (1/K)') plt.ylabel('ln($D_{ion}$)') plt.title('Arrhenius plot') plt.legend() plt.grid(True) plt.show() <p>The last technique to pick up in this class is data fitting. Later in the module, we will use more complex functions in high dimensions, but let's start with linear regression. There is no need to code this by hand as we can use a function in the machine learning package scikit-learn. The real power of Python is the quality and quantity of available libraries such as this one.</p> In\u00a0[\u00a0]: Copied! <pre>import numpy as np\nimport pandas as pd\n\nnum_points =  # Number of data points to generate\n\n# Generate random x-y data points\nx_data = np.random.uniform(0, 10, num_points)  # Adjust the range as needed\ny_data = np.random.uniform(0, 10, num_points)\n\n# Create a DataFrame\ndata = {'X': x_data, 'Y': y_data}\ndf = pd.DataFrame(data)\n\n# Print the DataFrame\nprint(df)\n</pre> import numpy as np import pandas as pd  num_points =  # Number of data points to generate  # Generate random x-y data points x_data = np.random.uniform(0, 10, num_points)  # Adjust the range as needed y_data = np.random.uniform(0, 10, num_points)  # Create a DataFrame data = {'X': x_data, 'Y': y_data} df = pd.DataFrame(data)  # Print the DataFrame print(df)  Code hint  Again you need to choose the number of points. 50 should be fine, but you have the power to decide.  In\u00a0[\u00a0]: Copied! <pre>from sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score, mean_squared_error\n\n# Perform linear regression\nX = df['X'].values.reshape(-1, 1)  # Reshape X for compatibility with sklearn\ny = df['Y'].values\nmodel = LinearRegression().fit(X, y)\ny_pred = model.predict(X)\n\n# Calculate error bars\nresiduals = y - y_pred\nerror_bars = np.abs(residuals)\n\n# Plot the linear regression line\nplt.figure(figsize=(5, 3)) \nplt.errorbar(df['X'], df['Y'], yerr=error_bars, fmt='o', color='skyblue', label='Prediction errors')\nplt.scatter(df['X'], df['Y'])\nplt.plot(df['X'], y_pred, color='red', label='Regression line')\nplt.xlabel('X')\nplt.ylabel('Y')\nplt.title('Linear regression')\nplt.legend()\nplt.show()\n</pre> from sklearn.linear_model import LinearRegression from sklearn.metrics import r2_score, mean_squared_error  # Perform linear regression X = df['X'].values.reshape(-1, 1)  # Reshape X for compatibility with sklearn y = df['Y'].values model = LinearRegression().fit(X, y) y_pred = model.predict(X)  # Calculate error bars residuals = y - y_pred error_bars = np.abs(residuals)  # Plot the linear regression line plt.figure(figsize=(5, 3))  plt.errorbar(df['X'], df['Y'], yerr=error_bars, fmt='o', color='skyblue', label='Prediction errors') plt.scatter(df['X'], df['Y']) plt.plot(df['X'], y_pred, color='red', label='Regression line') plt.xlabel('X') plt.ylabel('Y') plt.title('Linear regression') plt.legend() plt.show() <p>There are a number of useful analysis tools built into <code>sklearn</code>, which we can use to probe the model properties.</p> In\u00a0[\u00a0]: Copied! <pre># Print the model parameters and performance\ntry:\n    print(f'Slope: {model2.coef_[0]:.2f}')  # Assuming model.coef_ might be an array for multidimensional X\n    print(f'Intercept: {model2.intercept_:.2f}')\n    print(f'R^2 Score: {r2_score(y, y_pred):.3f}')  # R^2 - coefficient of determination\n    print(f'RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.3f}')  # Root Mean Squared Error\nexcept Exception as e:\n    print(\"Error in calculating model parameters or performance metrics:\", e)\n</pre> # Print the model parameters and performance try:     print(f'Slope: {model2.coef_[0]:.2f}')  # Assuming model.coef_ might be an array for multidimensional X     print(f'Intercept: {model2.intercept_:.2f}')     print(f'R^2 Score: {r2_score(y, y_pred):.3f}')  # R^2 - coefficient of determination     print(f'RMSE: {np.sqrt(mean_squared_error(y, y_pred)):.3f}')  # Root Mean Squared Error except Exception as e:     print(\"Error in calculating model parameters or performance metrics:\", e)  Code hint  Your model is not called `model2`. Try changing the name.  In\u00a0[\u00a0]: Copied! <pre>import numpy as np\n\n# Insert your values\nName = \"No Name\" # Replace with your name\nCID = 123446 # Replace with your College ID (as a numeric value with no leading 0s)\n\n# Set a random seed using the CID value\nCID = int(CID)\nnp.random.seed(CID)\n\n# Print the message\nprint(\"This is the work of \" + Name + \" [CID: \" + str(CID) + \"]\")\n</pre> import numpy as np  # Insert your values Name = \"No Name\" # Replace with your name CID = 123446 # Replace with your College ID (as a numeric value with no leading 0s)  # Set a random seed using the CID value CID = int(CID) np.random.seed(CID)  # Print the message print(\"This is the work of \" + Name + \" [CID: \" + str(CID) + \"]\") In\u00a0[\u00a0]: Copied! <pre>#Empty block for your answers\n</pre> #Empty block for your answers    In\u00a0[\u00a0]: Copied! <pre>#Empty block for your answers\n</pre> #Empty block for your answers    \ud83d\udcd3 Submission: When your notebook is complete in Google Colab, go to File &gt; Download and choose <code>.ipynb</code>. The completed file should be uploaded to Blackboard under assignments for MATE70026."},{"location":"lecture1.html#1-introduction","title":"1. Introduction\u00b6","text":""},{"location":"lecture1.html#getting-started","title":"\ud83d\udc4b Getting started\u00b6","text":"<p>Welcome to our first practical session!</p> <p>This is a Jupyter Notebook loaded inside a Jupyter Book. They are part of Project Jupyter, a suite of open-source tools. A Jupyter Notebook also allows you to run and easily share computer code. This combination makes Jupyter notebooks a useful tool for analysing data.</p> <p>Unlike spreadsheets or combinations of separate data analysis codes, you can collect descriptions and notes for individual experiments, links to the raw data collected, the computer code that performs any necessary data analysis, and the final figures generated with these data, ready for use in a report or published paper.</p> <p>There are a few components to be aware of:</p>"},{"location":"lecture1.html#python","title":"Python\u00b6","text":"<p>A working knowledge of the Python programming language is assumed for this course. If you are rusty, Chapters 1-4 of Datacamp cover the base concepts, as do many other online resources including Imperial's Introduction to Python course.</p> <p>Choose your degree programme:</p> MEng MSc <p>If MSc, have you completed the introductory Python course:</p> Yes No <p>Rate your current Python level:</p> Beginner Intermediate Advanced"},{"location":"lecture1.html#markdown","title":"Markdown\u00b6","text":"<p>Markdown is a markup language that allows easy formatting of text. It is widely used for creating and formatting online content. It is easier to read and write than html. A guide to the syntax can be found here.</p> <pre><code># Heading\n## Smaller heading\n### Even smaller heading\n</code></pre>"},{"location":"lecture1.html#github","title":"Github\u00b6","text":"<p>GitHub is a platform for writing and sharing code. There are many materials science projects hosted there, which enable researchers from around the world to contribute to their development. These notebooks are hosted on GitHub too. If you find an error, you can raise an issue or even better fix it yourself with a pull request.</p>"},{"location":"lecture1.html#live-coding","title":"Live coding\u00b6","text":"<p>The weekly notebooks are designed to be run online directly in your browser. You can activate the server by clicking the rocket icon on the top right and selecting <code>Live Code</code>. There is an option to open in Binder or Google Colab. Colab is more powerful, but the formatting won't be as nice. You can opt to install Python on your own computer with Anaconda and run the notebooks locally, but we do not offer support if things go wrong.</p>"},{"location":"lecture1.html#analyse-data-with-code","title":"Analyse data with code\u00b6","text":"<p>By programming a series of instructions, researchers can consistently obtain the same results from a given dataset. This approach enables us to share datasets and code, allowing other scientists to review, repeat and reuse the analysis.  The transparency and reproducibility of code-based analysis enhances research integrity and credibility, while minimising errors. It also enables efficient handling of large datasets and complex calculations, accelerating the exploration of different techniques.</p>"},{"location":"lecture1.html#running-code","title":"Running code\u00b6","text":"<p>Different programming languages can be used in Jupyter notebooks. We will be using Python 3. The large scientific community for Python means that well-developed resources exist for data processing and specific prewritten tools for manipulating and plotting data.</p> <p>Any code typed into a code cell can be run (executed) by pressing the <code>run</code> button. You can also run the selected code block using <code>Shift-Enter</code> combination on your keyboard.</p>"},{"location":"lecture1.html#plotting-with-matplotlib","title":"Plotting with Matplotlib\u00b6","text":""},{"location":"lecture1.html#using-a-dataframe","title":"Using a DataFrame\u00b6","text":"<p>A DataFrame organises data into a 2-dimensional table of rows and columns, much like a spreadsheet. They are useful tools to store, access, and modify large sets of data.</p> <p>In this module, we'll make use of Pandas to process input and output data for our machine learning models.</p>"},{"location":"lecture1.html#write-an-equation","title":"Write an equation\u00b6","text":""},{"location":"lecture1.html#link-an-image","title":"Link an image\u00b6","text":""},{"location":"lecture1.html#computational-science","title":"Computational science\u00b6","text":""},{"location":"lecture1.html#thermally-actived-diffusion","title":"Thermally-actived diffusion\u00b6","text":"<p>Ion transport in crystals is a fundamental process that underpins various technological applications, from batteries to semiconductor devices. Understanding the kinetics of ion movement within and between materials is crucial for optimising device performance.</p> <p>Like many chemical processes, solid-state diffusion transport is thermally activated. We can describe ion motion in a crystal using a familiar Arrhenius relationship.</p> <p>The diffusion coefficient of a species is given by $D_{ion} = D_0 \\cdot e^{-(\\frac{\\Delta E_a}{k_BT})}$, where:</p> <ul> <li>$D_{ion}$ is the diffusion coefficient for a particular ion,</li> <li>$D_0$ is the temperature-independent prefactor (containing an attempt frequency),</li> <li>$\\Delta E_a$ is the activation energy for diffusion,</li> <li>$k_B$ is the Boltzmann constant, and</li> <li>$T$ is the temperature.</li> </ul> <p>Let's write a function for it, which will take advantage of the wonderful NumPy package. It also uses the physical constants in SciPy, and explains the function with a docstring.</p>"},{"location":"lecture1.html#exercise-1","title":"\ud83d\udea8 Exercise 1\u00b6","text":"\ud83d\udca1 Coding exercises: The exercises are designed to apply what you have learned with room for creativity. It is fine to discuss solutions with your classmates, but the actual code should not be directly copied."},{"location":"lecture1.html#your-details","title":"Your details\u00b6","text":""},{"location":"lecture1.html#problem","title":"Problem\u00b6","text":"<p>Due to their importance in the electronics industry, the diffusion of atoms in semiconductors has been well studied for decades. Below is a set of data for impurity diffusion in crystalline Si [Source: Casey and Pearson (1975)]. It has been arranged into a DataFrame for your convenience.</p> <pre>import pandas as pd\n\ndata = {\n    'Impurity': ['B', 'Al', 'Ga', 'In', 'P', 'As', 'Sb', 'Bi'],\n    'Mass': [10.81, 26.98, 69.72, 114.82, 30.97, 74.92, 121.76, 208.98], # atomic mass in g/mol\n    'D0': [5.1, 8.0, 3.6, 16.5, 10.5, 60.0, 12.9, 1.03E3],  # cm2/sec\n    'Eact': [3.70, 3.47, 3.51, 3.91, 3.69, 4.20, 3.98, 4.63]  # eV\n}\n\ndf = pd.DataFrame(data)\nprint(df)\n</pre> <p>Two tasks will be given in class.</p>"},{"location":"lecture1.html#dive-deeper","title":"\ud83c\udf0a Dive deeper\u00b6","text":"<ul> <li><p>Level 1: Read Chapter 1 of Machine Learning Refined for a complementary introduction to the field.</p> </li> <li><p>Level 2: Taylor Sparks has a collection of video lectures on Python for Materials Engineers.</p> </li> <li><p>Level 3: If you are a matplotlib pro user, try plotly and bokeh for interactive visualisations.</p> </li> </ul>"},{"location":"resources.html","title":"Resources","text":"<p>This course primarily follows our book: N. T. Hung, A. R. T. Nugraha and R. Saito, Quantum ESPRESSO Course for Solid\u2011State Physics, Jenny Stanford Publishing, New York, 372 Pages, (2022).</p> <p>We strongly recommend referring to it for a deeper understanding of the concepts covered in the lectures.</p> <p>All input files used in the course can be downloaded from our GitHub repository: https://github.com/nguyen-group/QE-SSP/.</p>"},{"location":"resources.html#documents","title":"Documents","text":"<ul> <li> <p>Input description of pw.x</p> </li> <li> <p>Input description of bands.x</p> </li> <li> <p>Input description of dos.x</p> </li> <li> <p>Input description of pp.x</p> </li> <li> <p>Input description of dynmat.x</p> </li> <li> <p>Input description of matdyn.x</p> </li> <li> <p>Input description of q2r.x</p> </li> <li> <p>Input description of Wannier90</p> </li> </ul>"},{"location":"resources.html#workshops","title":"Workshops","text":"<ul> <li> <p>2024 School on Electron-Phonon Physics, Many-Body Perturbation Theory, and Computational Workflows, Austin, TX, 10-16 June 2024.</p> </li> <li> <p>Advanced Quantum ESPRESSO school: Hubbard and Koopmans functionals from linear response, University of Pavia, Pavia (Italy), Aug 28 \u2013 Sep 01, 2023.</p> </li> <li> <p>Efficient materials modelling on HPC with QUANTUM ESPRESSO, Yambo and BigDFT, EuroCC National Competence Center Sweden, Nov 14-17, 2022.</p> </li> <li> <p>Hubbard-Koopmans tutorial, Nov 9-11, 2022.</p> </li> <li> <p>MaX e-School on Advanced Materials and Molecular Modelling with Quantum ESPRESSO, May 17-28, 2021.</p> </li> <li> <p>Summer school on Advanced Materials and Molecular Modelling with Quantum ESPRESSO, Ljubljana, Slovenia, September 15-20 2019.</p> </li> </ul>"},{"location":"resources.html#other-resources","title":"Other Resources","text":"<ul> <li> <p>Quantum Espresso Tutorial</p> </li> <li> <p>Hands-on: 4 EASY install of Quantum Espresso on Ubuntu</p> </li> <li> <p>Installing quantum espresso</p> </li> </ul>"}]}