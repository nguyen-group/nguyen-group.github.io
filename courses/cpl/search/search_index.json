{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>This course, Computer Programming Language, introduces students to the fundamentals of Python programming. We begin with essential programming concepts, then explore how to visualize data through Python. The course further demonstrates how Python can be applied to machine learning and concludes with practical examples in physics and materials science, equipping students with programming skills relevant to modern scientific research.</p> <p>If you have corrections or suggestions, please raise an comment on our Github.</p>"},{"location":"contents/","title":"Contents","text":"<ol> <li> <p>Introduction to Python Programming   </p> <ul> <li>Overview of Python and its applications in science and engineering</li> </ul> </li> <li> <p>Setting Up the Development Environment</p> <ul> <li>Hands-on with VS Code and JupyterLab</li> <li>Simple practices for writing and running Python code</li> </ul> </li> <li> <p>Basic Python Programming </p> <ul> <li>Variables, data types, strings, lists, dictionaries</li> <li>Conditional statements and loops</li> <li>Writing and using functions, etc.</li> </ul> </li> <li> <p>Intermediate and Advanced Python</p> <ul> <li>Introduction to classes and object-oriented programming</li> <li>Common algorithms: sorting, searching, and recursion</li> <li>File I/O and exception handling, etc.</li> </ul> </li> <li> <p>Data Visualization with Matplotlib</p> <ul> <li>Introduction to Matplotlib and plotting basics</li> <li>Creating effective and publication-quality scientific plots</li> <li>Introduction to other libraries (e.g., Seaborn, etc.)</li> </ul> </li> <li> <p>Introduction to Machine Learning and Neural Networks</p> <ul> <li>Key concepts in machine learning</li> <li>Architecture of artificial neural networks (ANNs)</li> </ul> </li> <li> <p>Architecture of artificial neural networks (ANNs)</p> <ul> <li>Implementing a basic ANN using only Python and NumPy</li> <li>Hands-on training and testing with small datasets</li> </ul> </li> <li> <p>Advanced Neural Networks with TensorFlow or PyTorch</p> <ul> <li>Building deep neural networks with TensorFlow or PyTorch</li> <li>Training, evaluation, and model optimization</li> </ul> </li> <li> <p>Python for Materials Science</p> <ul> <li>Introduction to computational materials science</li> <li>Using Python to preprocess, postprocess, and visualize DFT data</li> <li>Practical example: analyzing band structures or density of states</li> </ul> </li> </ol>"},{"location":"lecture1/","title":"1. Introduction","text":"<p>Lecture slides</p>"},{"location":"lecture1/#1-introduction","title":"1. Introduction\u00b6","text":""},{"location":"lecture1/#11-getting-started","title":"1.1. \ud83d\udc4b Getting started\u00b6","text":"<p>Welcome to our first lecture!</p>"},{"location":"lecture1/#111-what-is-dft","title":"1.1.1. What is DFT?\u00b6","text":"<p>Density Functional Theory (DFT) is a computational quantum mechanical method used to calculate the ground state of the electronic structure of many-body systems, particularly atoms, molecules, and solids. Unlike traditional quantum mechanics methods, which solve the Schr\u00f6dinger equation for the many-electron wavefunction, DFT simplifies the problem by focusing on the electron density (in 3 dimensions) rather than the wavefunction (in $3N$ dimensions for $N$ electrons).</p>"},{"location":"lecture1/#112-functional","title":"1.1.2. Functional\u00b6","text":"<p>A functional is a function whose argument is itself a function. $f(x)$ is a function of the variable $x$ while $F[f]$ is a functional of the function $f$. $$ y = f(x) $$ $f$ is a function, it takes a number $x$ as input and output $y$ is also a number. $$ y = F[f(x)] $$ $F$ is a functional it takes function $f(x)$ as input and output $y$ is a number.</p>"},{"location":"lecture1/#13-functionals-in-dft","title":"1.3. Functionals in DFT\u00b6","text":"<p>The term \"functional\" in DFT comes from the fact that the total energy is calculated from the electron density function (which is a function of space) through the use of various functionals that describe different aspects of the system's energy.</p>"},{"location":"lecture1/#12-hohenberg-kohn-theorem","title":"1.2. Hohenberg-Kohn Theorem\u00b6","text":"\ud83d\udcd3 Reference: P. Hohenberg and W. Kohn, Inhomogeneous electron gas, Phys. Rev. 136, B864 (1964).  Theorem: There is a one\u2010to\u2010one correspondence between an external potential $\\mathcal{V}_{en}(\\textbf{r})$ and an electron density $n(\\textbf{r})$.  <p>Since the Hamiltonians is determined by the external potential, the Hohenberg-Kohn theorem tell us the two different Hamiltonian cannot have the same ground-state electron density. The theorem leads to two important consequences:</p> Corollary 1: The electron density $n(\\textbf{r})$ uniquely specifies the external potential $\\mathcal{V}_{en}(\\textbf{r})$ and hence the Hamiltonian $\\mathcal{H}$.  <p>The Schr\u00f6dinger equation says how we can get the wavefunction from a given potential. Once solved the wavefunction (which could be difficul due to the high\u2010dimensional partial differential equation), we can determine the density or any other properties. Now Corollary 1 says the opposite is also true. For a given density, the potential can be uniquely determined. Thus, it is possible to define the ground-state energy as a function of electronic density.</p> Corollary 2: The ground-state total energy can be obtained by minimizing an energy functional $E[n(\\textbf{r})]$ with respect to the electron density $n(\\textbf{r})$.  <p>The ground state energy can therefore be found by minimizing $E[n(\\textbf{r})]$ instead of solving for the many-electron wavefunction. However, the Hohenberg-Kohn theorems do not tell us how the energy depends on the electron density. It is noted that the DFT can have an exact solution if and only if $E[n(\\textbf{r})]$ is known exactly. In reality, apart from some special cases, the exact $E[n(\\textbf{r})]$ is unknown and only approximate functionals are used.</p>"},{"location":"lecture1/#13-kohn-sham-equation","title":"1.3. Kohn-Sham equation\u00b6","text":"\ud83d\udcd3 Reference: P. Hohenberg and W. Kohn, Self-consistent equations including exchange and correlation effects, Phys. Rev. 140, A1133  (1965).  <p>For any system of $N$ interacting electrons in a given external potential $\\mathcal{V}_{en} (\\textbf{r})$ (i.e., Coulomb attraction between electrons and nuclei), there is a \"virtual system\" of $N$ non-interacting electrons with exactly the same density as the interacting one. The non-interacting electrons subjected to a effective external potential $\\mathcal{V}_{eff} (\\textbf{r})$ as: $$ \\left[-\\frac{\\hbar^2 \\nabla^2}{2m} + \\mathcal{V}_{eff}(\\textbf{r}) \\right] \\psi_i(\\textbf{r}) = \\epsilon_i \\psi_i(\\textbf{r}), $$ where the effective external potential is given by: $$ \\mathcal{V}_{eff}(\\textbf{r}) = \\mathcal{V}_{en}(\\textbf{r}) + \\mathcal{V}_{H}(\\textbf{r}) + \\mathcal{V}_{xc}(\\textbf{r}), $$ where the Hartree potential, which describes electrostatic interaction of electronic cloud, is defined by: $$ \\mathcal{V}_{H}(\\textbf{r}) = \\int \\frac{n(\\textbf{r})}{|\\textbf{r} - \\textbf{r}'|} \\mathrm{d}\\textbf{r}', $$ and the electron density is given by: $$ n(\\textbf{r}) = \\sum_i f_i |\\psi_i (\\textbf{r})|^2, $$ where $f_i$ is the occupation factor of electrons ($0 \\le f_i \\le 1$). The Kohn-Sham equation looks like single particle Schr\u00f6dinger equation, however $\\mathcal{V}_{H}(\\textbf{r})$ and $\\mathcal{V}_{xc}(\\textbf{r})$ (exchange-correlation potential, it includes all the remaining/unknown energy corrections) terms depend on $n(\\textbf{r})$ i.e., on $\\psi_i$ which in turn depends on $\\mathcal{V}_{en}(\\textbf{r})$. Therefore the problem is non-linear. It is usually solved computationally by starting from a trial potential and iterate to self-consistency</p>"},{"location":"lecture1/#131-self-consistent-solution","title":"1.3.1. Self-Consistent Solution\u00b6","text":"<p>The Kohn-Sham equations are solved iteratively:</p> <ul> <li>Guess $n(\\textbf{r})$.</li> <li>Calculate $\\mathcal{V}_{eff}(\\textbf{r})$.</li> <li>Solve for $\\psi_i$ and update $n(\\textbf{r}) = \\sum_i f_i |\\psi_i (\\textbf{r})|^2$.</li> <li>Repeat until convergence.</li> </ul>"},{"location":"lecture1/#14-exchange-correlation-functional","title":"1.4. Exchange-correlation functional\u00b6","text":""},{"location":"lecture1/#141-local-density-approximation-lda","title":"1.4.1. Local Density Approximation (LDA)\u00b6","text":"\ud83d\udcd3 Reference: J. P. Perdew and A. Zunger, Self-interaction correction to density-functional approximations for many-electron systems, Phys. Rev. B 23, 5048 (1981).  <p>The LDA is a widely used approximation the exchange-correlation energy of a system by assuming that the electronic density varies slowly and treating the local density as a uniform electron gas. In this case, the exchange-correlation energy at each point in space as being the same as that of a uniform electron gas with the same electron density at that point. Thus, the LDA is given by:</p> <p>$$ E_{xc} = \\int n(\\textbf{r}) \\epsilon_{xc}(n(\\textbf{r})) d\\textbf{r} $$ and $$ \\mathcal{V}_{xc}(\\textbf{r}) = \\epsilon_{xc}(n(\\textbf{r})) + n(\\textbf{r})\\frac{d\\epsilon_{xc}(n)}{dn}\\bigg\\rvert_{n=n(\\textbf{r})}, $$ where $\\epsilon_{xc}(n)$ is the exchange-correlation energy per electron, which is obtained for the homogeneous electron gas of density $n$ (using Quantum Monte Carlo techniques) and fitted to some analytic form. LDA is computationally cheap compared to more advanced functionals, making it useful for large systems. However, the LDA can lead to inaccuracies in systems with rapidly varying densities (e.g., strongly correlated materials, surfaces, etc.).</p>"},{"location":"lecture1/#142-generalized-gradient-approximation-gga","title":"1.4.2. Generalized Gradient Approximation (GGA)\u00b6","text":"\ud83d\udcd3 Reference: J. P. Perdew, K. Burke, and M. Ernzerhof, Generalized gradient approximation made simple, Phys. Rev. Lett. 77, 3865 (1997).  <p>The GGA is one of the approximations to the exchange-correlation energy functional, which improves the accuracy of exchange-correlation energy functionals by incorporating density gradients, going beyond the LDA. Thus, the GGA depends on both the local density and the local gradient of the density as: $$ E_{xc} = \\int n(\\textbf{r}) \\epsilon_{GGA}(n(\\textbf{r}), |\\nabla n(\\textbf{r})|) d\\textbf{r}. $$</p> <p>Unlike LDA, GGA considers how the electron density varies in space, improving accuracy for inhomogeneous systems. However, both the LDA and GGA underestimate band gaps in semiconductors and insulators and often fail for van der Waals (dispersion) interactions. In oder to solve these issues, there are more advanced functionals: Meta-GGA (e.g., SCAN), hybrids (e.g., B3LYP), nonlocal functionals for van der Waals forces, Grimme's DFT+D (a semi-empirical correction to GGA). They usually produces more accurate result, but computationally more expensive and sometimes numerically unstable.</p>"},{"location":"lecture1/#15-quantum-espresso","title":"1.5. Quantum ESPRESSO\u00b6","text":"<p>Quantum ESPRESSO (QE) is one of the most used packages for first\u2010principles calculations with the DFT, and it has been developing continuously; thanks to its open\u2010source and excellent community support. The abbreviation ESPRESSO stands for \u201cESPRESSO = opEn Source Package for Research in Electronic Structure, Simulation, and Optimization.\u201d It is completely FREE and easily installed on many platforms.</p> <p>We can install QE on our personal laptops or desktops to run relatively less computationally intensive calculations. In particular, the almost of hands-on tutorials in this course can be run on a personal laptop. However, if we intend to perform computationally heavy tasks, we will need access to better computing resources with a larger number of CPU (or GPU) cores, memory, bandwidth, and disk IO.</p>"},{"location":"lecture1/#151-installing-qe-on-ubuntu","title":"1.5.1. Installing QE on Ubuntu\u00b6","text":"<p>Easiest way to install Quantum Espresso is from the package manager of respective Ubuntu distribution. This should work fine for us and this is recommended option for this course. Following commands are for Ubuntu/Debian:</p> <ul> <li>Update list of repositories and upgrade the system</li> </ul> <pre>sudo apt update &amp;&amp; sudo apt upgrade\n</pre> <ul> <li>Important development tools and libraries: Git, wget, gcc/g++/gfortran, LAPACK, FFTW, openmpi (mpirun)</li> </ul> <pre>sudo apt -y install git wget build-essential\nsudo apt -y install g++ gfortran\nsudo apt -y install liblapack-dev libfftw3-dev libopenmpi-dev\n</pre> <ul> <li>Quantum ESPRESSO and Wannier90 from apt repository</li> </ul> <pre>sudo apt -y install quantum-espresso wannier90\n</pre> <ul> <li>Additional tools</li> </ul> <pre>sudo apt -y install xcrysden gnuplot\nsudo apt -y install python3-dev jupyter-server\nsudo apt -y install python3-numpy python3-scipy python3-sympy python3-matplotlib\n</pre>"},{"location":"lecture1/#152-installing-qe-on-windows","title":"1.5.2. Installing QE on Windows\u00b6","text":"<p>For Windows, we recommend to use Windows subsystem for Linux (WSL) as follows:</p> <ul> <li>Open PowerShell as Administrator and run:</li> </ul> <pre>wsl --install\n</pre> <ul> <li><p>Restart your computer if needed.</p> </li> <li><p>Open the \"Windows Terminal\" and install a Linux distribution (Ubuntu is recommended).</p> </li> <li><p>Install QE for Ubuntu as shown above.</p> </li> </ul> <p>A Youtube video (not made by us) shows how to Quantum ESPRESSO 7.4 on Windows 11 (WSL2).</p>"},{"location":"lecture1/#153-installing-qe-on-macos","title":"1.5.3. Installing QE on MacOS\u00b6","text":"<p>We do not recommend using QE on macOS. I tested it on my MacBook Pro M1 and found it to be unstable. However, if you wish to install QE on a MacOS, you can refer to https://github.com/nguyen-group/QE-SSP/discussions/9.</p>"},{"location":"lecture1/#154-obtaining-example-files-for-this-course","title":"1.5.4. Obtaining example files for this course\u00b6","text":"<p>We provide example input/output files of QE calculations on the GitHub. You can download them by using the following command:</p> <pre>git clone https://github.com/nguyen-group/QE-SSP.git\n</pre>"},{"location":"lecture1/#16-exercise","title":"1.6. Exercise\u00b6","text":"<ul> <li>Install QE on your PC.</li> </ul>"},{"location":"lecture1/#17-dive-deeper","title":"1.7. Dive deeper\u00b6","text":"<ul> <li><p>Level 1: Read Chapter 4 of \"Quantum ESPRESSO for Solid State Physics\" book for understanding DFT.</p> </li> <li><p>Level 2: Install Intel OneAPI Base Toolkit, then install QE with Intel MKL for optimized performance.</p> </li> </ul>"},{"location":"resources/","title":"Resources","text":"<p>All input files used in the course can be downloaded from our GitHub repository: https://github.com/nguyen-group/CPL/.</p>"},{"location":"resources/#textbook-or-designated-reading","title":"Textbook or Designated Reading:","text":"<ul> <li> <p>Python Crash Course, 2nd Edition: A Hands-On, Project-Based Introduction to Programming, Eric Matthes, 2019</p> </li> <li> <p>Fluent Python: Clear, Concise, and Effective Programming, Luciano Ramalho, 2015</p> </li> <li> <p>Python Data Science Handbook: Essential Tools for Working with Data, Jake Vanderplas, 2017</p> </li> <li> <p>Hands-On Machine Learning with Scikit-Learn and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems, Aurelien Geron, 2017</p> </li> <li> <p>Introduction To Solid State Physics, Charles Kittel, 2004</p> </li> </ul> <p>Note: Additional journal articles, reviews, and materials will be given out in classes.</p>"},{"location":"resources/#other-references","title":"Other References:","text":"<ul> <li> <p>https://github.com/nguyen-group/Neural_Networks_with_Python</p> </li> <li> <p>https://github.com/Asabeneh/30-Days-Of-Python</p> </li> <li> <p>https://github.com/CodeWithHarry/The-Ultimate-Python-Course</p> </li> </ul>"}]}